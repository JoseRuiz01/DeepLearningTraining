{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10792469,"sourceType":"datasetVersion","datasetId":6697557},{"sourceId":10821714,"sourceType":"datasetVersion","datasetId":6719064}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Assignment: Image recognition\n- Alumno 1: José Antonio Ruiz Heredia\n- Alumno 2: Álvaro Honrubia\n- Alumno 3: Hector Carlos Flores Reynoso \n\nThe goals of the assignment are:\n* Develop proficiency in using Tensorflow/Keras for training Neural Nets (NNs).\n* Put into practice the acquired knowledge to optimize the parameters and architecture of a feedforward Neural Net (ffNN), in the context of an image recognition problem.\n* Put into practice NNs specially conceived for analysing images. Design and optimize the parameters of a Convolutional Neural Net (CNN) to deal with previous task.\n* Train popular architectures from scratch (e.g., GoogLeNet, VGG, ResNet, ...), and compare the results with the ones provided by their pre-trained versions using transfer learning.\n\nFollow the link below to download the classification data set  “xview_recognition”: [https://drive.upm.es/s/4oNHlRFEd71HXp4](https://drive.upm.es/s/4oNHlRFEd71HXp4)","metadata":{"editable":true,"id":"QYuALZOG-AMq","slideshow":{"slide_type":""},"tags":[]}},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.config.list_physical_devices('GPU'))","metadata":{"ExecuteTime":{"end_time":"2024-10-26T00:00:21.031186Z","start_time":"2024-10-26T00:00:17.131476Z"},"editable":true,"slideshow":{"slide_type":""},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T14:09:08.576741Z","iopub.execute_input":"2025-03-03T14:09:08.577097Z","iopub.status.idle":"2025-03-03T14:09:09.207995Z","shell.execute_reply.started":"2025-03-03T14:09:08.577069Z","shell.execute_reply":"2025-03-03T14:09:09.206861Z"}},"outputs":[{"name":"stdout","text":"[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import uuid\nimport numpy as np\n\nclass GenericObject:\n    \"\"\"\n    Generic object data.\n    \"\"\"\n    def __init__(self):\n        self.id = uuid.uuid4()\n        self.bb = (-1, -1, -1, -1)\n        self.category= -1\n        self.score = -1\n\nclass GenericImage:\n    \"\"\"\n    Generic image data.\n    \"\"\"\n    def __init__(self, filename):\n        self.filename = filename\n        self.tile = np.array([-1, -1, -1, -1])  # (pt_x, pt_y, pt_x+width, pt_y+height)\n        self.objects = list([])\n\n    def add_object(self, obj: GenericObject):\n        self.objects.append(obj)","metadata":{"ExecuteTime":{"end_time":"2024-10-26T00:00:21.066937Z","start_time":"2024-10-26T00:00:21.059126Z"},"editable":true,"id":"OYtqD3Oh-AMw","slideshow":{"slide_type":""},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T14:09:09.209316Z","iopub.execute_input":"2025-03-03T14:09:09.209727Z","iopub.status.idle":"2025-03-03T14:09:09.229594Z","shell.execute_reply.started":"2025-03-03T14:09:09.209687Z","shell.execute_reply":"2025-03-03T14:09:09.228668Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"categories = {0: 'Cargo plane', 1: 'Helicopter', 2: 'Small car', 3: 'Bus', 4: 'Truck', 5: 'Motorboat', 6: 'Fishing vessel', 7: 'Dump truck', 8: 'Excavator', 9: 'Building', 10: 'Storage tank', 11: 'Shipping container'}","metadata":{"ExecuteTime":{"end_time":"2024-10-26T00:00:21.153693Z","start_time":"2024-10-26T00:00:21.149079Z"},"id":"I_GygShu-AMz","trusted":true,"execution":{"iopub.status.busy":"2025-03-03T14:09:09.231346Z","iopub.execute_input":"2025-03-03T14:09:09.231586Z","iopub.status.idle":"2025-03-03T14:09:09.244035Z","shell.execute_reply.started":"2025-03-03T14:09:09.231566Z","shell.execute_reply":"2025-03-03T14:09:09.243072Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install rasterio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T14:09:09.245357Z","iopub.execute_input":"2025-03-03T14:09:09.245677Z","iopub.status.idle":"2025-03-03T14:09:15.087161Z","shell.execute_reply.started":"2025-03-03T14:09:09.245645Z","shell.execute_reply":"2025-03-03T14:09:15.086268Z"}},"outputs":[{"name":"stdout","text":"Collecting rasterio\n  Downloading rasterio-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\nCollecting affine (from rasterio)\n  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\nRequirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (25.1.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2025.1.31)\nRequirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\nRequirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\nRequirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.26.4)\nRequirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from rasterio) (3.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24->rasterio) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24->rasterio) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.24->rasterio) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.24->rasterio) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.24->rasterio) (2024.2.0)\nDownloading rasterio-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading affine-2.4.0-py3-none-any.whl (15 kB)\nInstalling collected packages: affine, rasterio\nSuccessfully installed affine-2.4.0 rasterio-1.4.3\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import warnings\nimport rasterio\nimport numpy as np\n\ndef load_geoimage(filename):\n    warnings.filterwarnings('ignore', category=rasterio.errors.NotGeoreferencedWarning)\n    src_raster = rasterio.open('../input/xview-recognition/xview_recognition/'+filename, 'r')\n    # RasterIO to OpenCV (see inconsistencies between libjpeg and libjpeg-turbo)\n    input_type = src_raster.profile['dtype']\n    input_channels = src_raster.count\n    img = np.zeros((src_raster.height, src_raster.width, src_raster.count), dtype=input_type)\n    for band in range(input_channels):\n        img[:, :, band] = src_raster.read(band+1)\n    return img","metadata":{"ExecuteTime":{"end_time":"2024-10-26T00:00:21.292654Z","start_time":"2024-10-26T00:00:21.205321Z"},"editable":true,"id":"fRBA7ReQ-AM0","slideshow":{"slide_type":""},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T14:09:15.088172Z","iopub.execute_input":"2025-03-03T14:09:15.088400Z","iopub.status.idle":"2025-03-03T14:09:15.460409Z","shell.execute_reply.started":"2025-03-03T14:09:15.088378Z","shell.execute_reply":"2025-03-03T14:09:15.459748Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"#### Training\nDesign and train a ffNN to deal with the “xview_recognition” classification task.","metadata":{"id":"diNBB3qy-AM2"}},{"cell_type":"code","source":"import json\n\n# Load database\njson_file = '../input/xview-recognition/xview_recognition/xview_ann_train.json'\nwith open(json_file) as ifs:\n    json_data = json.load(ifs)\nifs.close()","metadata":{"ExecuteTime":{"end_time":"2024-10-26T00:00:21.416449Z","start_time":"2024-10-26T00:00:21.311510Z"},"editable":true,"id":"Orto292C-AM3","slideshow":{"slide_type":""},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T14:09:15.461122Z","iopub.execute_input":"2025-03-03T14:09:15.461851Z","iopub.status.idle":"2025-03-03T14:09:15.621518Z","shell.execute_reply.started":"2025-03-03T14:09:15.461829Z","shell.execute_reply":"2025-03-03T14:09:15.620574Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import numpy as np\n\ncounts = dict.fromkeys(categories.values(), 0)\nanns = []\nfor json_img, json_ann in zip(json_data['images'].values(), json_data['annotations'].values()):\n    image = GenericImage(json_img['filename'])\n    image.tile = np.array([0, 0, json_img['width'], json_img['height']])\n    obj = GenericObject()\n    obj.bb = (int(json_ann['bbox'][0]), int(json_ann['bbox'][1]), int(json_ann['bbox'][2]), int(json_ann['bbox'][3]))\n    obj.category = json_ann['category_id']\n    # Resampling strategy to reduce training time\n    counts[obj.category] += 1\n    image.add_object(obj)\n    anns.append(image)\nprint(counts)","metadata":{"ExecuteTime":{"end_time":"2024-10-26T00:00:22.874518Z","start_time":"2024-10-26T00:00:22.204948Z"},"id":"4GjFLHs4-AM4","outputId":"5581df22-d4e9-42ac-9f94-061fd8c7acd9","trusted":true,"execution":{"iopub.status.busy":"2025-03-03T14:09:15.622432Z","iopub.execute_input":"2025-03-03T14:09:15.622736Z","iopub.status.idle":"2025-03-03T14:09:16.045511Z","shell.execute_reply.started":"2025-03-03T14:09:15.622713Z","shell.execute_reply":"2025-03-03T14:09:16.044551Z"}},"outputs":[{"name":"stdout","text":"{'Cargo plane': 635, 'Helicopter': 70, 'Small car': 4290, 'Bus': 2155, 'Truck': 2746, 'Motorboat': 1069, 'Fishing vessel': 706, 'Dump truck': 1236, 'Excavator': 789, 'Building': 4689, 'Storage tank': 1469, 'Shipping container': 1523}\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nanns_train, anns_valid = train_test_split(anns, test_size=0.1, random_state=1, shuffle=True)\nprint('Number of training images: ' + str(len(anns_train)))\nprint('Number of validation images: ' + str(len(anns_valid)))","metadata":{"ExecuteTime":{"end_time":"2024-10-26T00:00:23.656800Z","start_time":"2024-10-26T00:00:23.123245Z"},"id":"NriAECvS-AM6","trusted":true,"execution":{"iopub.status.busy":"2025-03-03T14:09:16.047938Z","iopub.execute_input":"2025-03-03T14:09:16.048170Z","iopub.status.idle":"2025-03-03T14:09:16.430622Z","shell.execute_reply.started":"2025-03-03T14:09:16.048149Z","shell.execute_reply":"2025-03-03T14:09:16.429840Z"}},"outputs":[{"name":"stdout","text":"Number of training images: 19239\nNumber of validation images: 2138\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, LeakyReLU, BatchNormalization\nfrom tensorflow.keras.initializers import HeNormal\nfrom tensorflow.keras.regularizers import L1, L2  # Lasso regularizer (L1) & Ridge regularizer (L2)\n\nprint('Load model')\nmodel = Sequential()\n\n# Input layer\nmodel.add(Flatten(input_shape=(224, 224, 3)))\n\n# Hidden Layer 1\nmodel.add(Dense(units=1024, kernel_initializer=HeNormal(), kernel_regularizer=L2(1e-4)))\n                \n#,bias_regularizer=L1(1e-4), activity_regularizer=L1(1e-5)))  \nmodel.add(BatchNormalization()) \nmodel.add(LeakyReLU(alpha=0.01)) \nmodel.add(Dropout(rate=0.4))\n\n# Hidden Layer 2\nmodel.add(Dense(units=512, kernel_initializer=HeNormal(), kernel_regularizer=L2(1e-4)))\n               # ,bias_regularizer=L1(1e-4), activity_regularizer=L1(1e-5)))  \nmodel.add(BatchNormalization()) \nmodel.add(LeakyReLU(alpha=0.01))\nmodel.add(Dropout(rate=0.3))\n\n# Hidden Layer 3\nmodel.add(Dense(units=256, kernel_initializer=HeNormal(), kernel_regularizer=L2(1e-4)))\n                #,bias_regularizer=L1(1e-4), activity_regularizer=L1(1e-5)))  \nmodel.add(BatchNormalization()) \nmodel.add(LeakyReLU(alpha=0.01))\nmodel.add(Dropout(rate=0.2))\n\n# Hidden Layer 4\nmodel.add(Dense(units=128, kernel_initializer=HeNormal(), kernel_regularizer=L2(1e-4)))\n               # ,bias_regularizer=L1(1e-4), activity_regularizer=L1(1e-5)))  \nmodel.add(BatchNormalization()) \nmodel.add(LeakyReLU(alpha=0.01))\nmodel.add(Dropout(rate=0.1))\n\n# Output layer\nmodel.add(Dense(len(categories), activation='softmax'))\n\nmodel.summary()\n","metadata":{"ExecuteTime":{"end_time":"2024-10-26T00:00:25.056806Z","start_time":"2024-10-26T00:00:24.261581Z"},"id":"BNkjbY2e-AM7","outputId":"47bde031-306f-464e-8e22-cc70a7fb7c67","trusted":true,"execution":{"iopub.status.busy":"2025-03-03T14:09:16.431764Z","iopub.execute_input":"2025-03-03T14:09:16.432280Z","iopub.status.idle":"2025-03-03T14:09:18.386453Z","shell.execute_reply.started":"2025-03-03T14:09:16.432255Z","shell.execute_reply":"2025-03-03T14:09:18.385770Z"}},"outputs":[{"name":"stdout","text":"Load model\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150528\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │     \u001b[38;5;34m154,141,696\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │           \u001b[38;5;34m4,096\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m524,800\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │           \u001b[38;5;34m1,548\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150528</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │     <span style=\"color: #00af00; text-decoration-color: #00af00\">154,141,696</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,548</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m154,839,948\u001b[0m (590.67 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">154,839,948</span> (590.67 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m154,836,108\u001b[0m (590.65 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">154,836,108</span> (590.65 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,840\u001b[0m (15.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,840</span> (15.00 KB)\n</pre>\n"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\n## Learning rate is changed (0.0001)\n## beta 1: controls the exponential decay rate for the 1st moment (0.8)\n## beta 2: controls the 2nd moment decay, fine-tuned for specific tasks. (0.999)\n## epsilon: avoid numerical instability (1e-9)\n\nopt = Adam(learning_rate=5e-4, beta_1=0.8, beta_2=0.999, epsilon=1e-9, amsgrad=True, clipnorm=1.0)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"ExecuteTime":{"end_time":"2024-10-26T00:00:25.467525Z","start_time":"2024-10-26T00:00:25.434068Z"},"id":"-aSlKtG6-AM7","trusted":true,"execution":{"iopub.status.busy":"2025-03-03T14:09:18.387246Z","iopub.execute_input":"2025-03-03T14:09:18.387539Z","iopub.status.idle":"2025-03-03T14:09:18.402214Z","shell.execute_reply.started":"2025-03-03T14:09:18.387508Z","shell.execute_reply":"2025-03-03T14:09:18.401482Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from tensorflow.keras.callbacks import TerminateOnNaN, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\n# Callbacks\nmodel_checkpoint = ModelCheckpoint('model.keras', monitor='val_accuracy', verbose=1, save_best_only=True)\n## Change the factor to 0.5 and patience to 5 to make the learning rate decrease.\nreduce_lr = ReduceLROnPlateau('val_accuracy', factor=0.5, patience=5, verbose=1)\n## Reduce the patience to stop early if the model doesn’t improve\nearly_stop = EarlyStopping('val_accuracy', patience=10, verbose=1)\nterminate = TerminateOnNaN()\ncallbacks = [model_checkpoint, reduce_lr, early_stop, terminate]","metadata":{"ExecuteTime":{"end_time":"2024-10-26T00:00:26.254555Z","start_time":"2024-10-26T00:00:26.243908Z"},"id":"GGAJEfpB-AM8","trusted":true,"execution":{"iopub.status.busy":"2025-03-03T14:09:18.403074Z","iopub.execute_input":"2025-03-03T14:09:18.403336Z","iopub.status.idle":"2025-03-03T14:09:18.409950Z","shell.execute_reply.started":"2025-03-03T14:09:18.403303Z","shell.execute_reply":"2025-03-03T14:09:18.409114Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def generator_images(objs, batch_size, do_shuffle=False):\n    while True:\n        if do_shuffle:\n            np.random.shuffle(objs)\n        groups = [objs[i:i+batch_size] for i in range(0, len(objs), batch_size)]\n        for group in groups:\n            images, labels = [], []\n            for (filename, obj) in group:\n                # Load image\n                images.append(load_geoimage(filename))\n                probabilities = np.zeros(len(categories))\n                probabilities[list(categories.values()).index(obj.category)] = 1\n                labels.append(probabilities)\n            images = np.array(images).astype(np.float32)\n            labels = np.array(labels).astype(np.float32)\n            yield images, labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T14:09:18.410805Z","iopub.execute_input":"2025-03-03T14:09:18.411051Z","iopub.status.idle":"2025-03-03T14:09:18.420044Z","shell.execute_reply.started":"2025-03-03T14:09:18.411032Z","shell.execute_reply":"2025-03-03T14:09:18.419337Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Generate the list of objects from annotations\nobjs_train = [(ann.filename, obj) for ann in anns_train for obj in ann.objects]\nobjs_valid = [(ann.filename, obj) for ann in anns_valid for obj in ann.objects]\n# Generators\nbatch_size = 128 ## Increase bach size (128) \ntrain_generator = generator_images(objs_train, batch_size, do_shuffle=True)\nvalid_generator = generator_images(objs_valid, batch_size, do_shuffle=False)","metadata":{"ExecuteTime":{"end_time":"2024-10-26T00:00:27.058834Z","start_time":"2024-10-26T00:00:27.022627Z"},"id":"Yht-QqUH-AM8","trusted":true,"execution":{"iopub.status.busy":"2025-03-03T14:09:18.420786Z","iopub.execute_input":"2025-03-03T14:09:18.421029Z","iopub.status.idle":"2025-03-03T14:09:18.451391Z","shell.execute_reply.started":"2025-03-03T14:09:18.421010Z","shell.execute_reply":"2025-03-03T14:09:18.450337Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import math\nimport numpy as np\n\nprint('Training model')\nepochs = 100 ## Increase epochs (60) \ntrain_steps = math.ceil(len(objs_train)/batch_size)\nvalid_steps = math.ceil(len(objs_valid)/batch_size)\nh = model.fit(train_generator, steps_per_epoch=train_steps, validation_data=valid_generator, validation_steps=valid_steps, epochs=epochs, callbacks=callbacks, verbose=1)\n# Best validation model\nbest_idx = int(np.argmax(h.history['val_accuracy']))\nbest_value = np.max(h.history['val_accuracy'])\nprint('Best validation model: epoch ' + str(best_idx+1), ' - val_accuracy ' + str(best_value))","metadata":{"ExecuteTime":{"start_time":"2024-10-26T00:00:27.913670Z"},"editable":true,"id":"TrfpdECs-AM9","jupyter":{"is_executing":true},"outputId":"21d89b78-d94c-442e-9bc2-517654c0b614","slideshow":{"slide_type":""},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T14:09:18.452203Z","iopub.execute_input":"2025-03-03T14:09:18.452437Z","execution_failed":"2025-03-03T17:42:50.401Z"}},"outputs":[{"name":"stdout","text":"Training model\nEpoch 1/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.2887 - loss: 2.5782\nEpoch 1: val_accuracy improved from -inf to 0.40552, saving model to model.keras\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1220s\u001b[0m 8s/step - accuracy: 0.2891 - loss: 2.5768 - val_accuracy: 0.4055 - val_loss: 2.3827 - learning_rate: 5.0000e-04\nEpoch 2/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658ms/step - accuracy: 0.4395 - loss: 2.0623\nEpoch 2: val_accuracy improved from 0.40552 to 0.40692, saving model to model.keras\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 816ms/step - accuracy: 0.4395 - loss: 2.0622 - val_accuracy: 0.4069 - val_loss: 2.2561 - learning_rate: 5.0000e-04\nEpoch 3/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661ms/step - accuracy: 0.4633 - loss: 1.9539\nEpoch 3: val_accuracy did not improve from 0.40692\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 733ms/step - accuracy: 0.4632 - loss: 1.9539 - val_accuracy: 0.3849 - val_loss: 2.6076 - learning_rate: 5.0000e-04\nEpoch 4/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644ms/step - accuracy: 0.4730 - loss: 1.9131\nEpoch 4: val_accuracy improved from 0.40692 to 0.42937, saving model to model.keras\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 795ms/step - accuracy: 0.4729 - loss: 1.9132 - val_accuracy: 0.4294 - val_loss: 2.0930 - learning_rate: 5.0000e-04\nEpoch 5/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4761 - loss: 1.9006\nEpoch 5: val_accuracy improved from 0.42937 to 0.43031, saving model to model.keras\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 2s/step - accuracy: 0.4761 - loss: 1.9005 - val_accuracy: 0.4303 - val_loss: 2.1323 - learning_rate: 5.0000e-04\nEpoch 6/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4799 - loss: 1.8789\nEpoch 6: val_accuracy did not improve from 0.43031\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 2s/step - accuracy: 0.4800 - loss: 1.8789 - val_accuracy: 0.4284 - val_loss: 2.0609 - learning_rate: 5.0000e-04\nEpoch 7/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773ms/step - accuracy: 0.4895 - loss: 1.8617\nEpoch 7: val_accuracy did not improve from 0.43031\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 777ms/step - accuracy: 0.4895 - loss: 1.8617 - val_accuracy: 0.3948 - val_loss: 2.2182 - learning_rate: 5.0000e-04\nEpoch 8/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692ms/step - accuracy: 0.4884 - loss: 1.8475\nEpoch 8: val_accuracy improved from 0.43031 to 0.45510, saving model to model.keras\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 790ms/step - accuracy: 0.4884 - loss: 1.8475 - val_accuracy: 0.4551 - val_loss: 2.0112 - learning_rate: 5.0000e-04\nEpoch 9/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4966 - loss: 1.8420\nEpoch 9: val_accuracy did not improve from 0.45510\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 1s/step - accuracy: 0.4966 - loss: 1.8420 - val_accuracy: 0.4528 - val_loss: 2.0160 - learning_rate: 5.0000e-04\nEpoch 10/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748ms/step - accuracy: 0.4987 - loss: 1.8191\nEpoch 10: val_accuracy improved from 0.45510 to 0.46445, saving model to model.keras\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 843ms/step - accuracy: 0.4986 - loss: 1.8191 - val_accuracy: 0.4645 - val_loss: 1.9386 - learning_rate: 5.0000e-04\nEpoch 11/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4921 - loss: 1.8171\nEpoch 11: val_accuracy did not improve from 0.46445\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.4921 - loss: 1.8171 - val_accuracy: 0.4341 - val_loss: 2.0152 - learning_rate: 5.0000e-04\nEpoch 12/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720ms/step - accuracy: 0.5032 - loss: 1.8000\nEpoch 12: val_accuracy did not improve from 0.46445\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 724ms/step - accuracy: 0.5032 - loss: 1.8000 - val_accuracy: 0.4359 - val_loss: 2.0850 - learning_rate: 5.0000e-04\nEpoch 13/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692ms/step - accuracy: 0.5055 - loss: 1.7872\nEpoch 13: val_accuracy did not improve from 0.46445\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 696ms/step - accuracy: 0.5055 - loss: 1.7872 - val_accuracy: 0.4415 - val_loss: 1.9943 - learning_rate: 5.0000e-04\nEpoch 14/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690ms/step - accuracy: 0.5108 - loss: 1.7811\nEpoch 14: val_accuracy did not improve from 0.46445\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 694ms/step - accuracy: 0.5108 - loss: 1.7811 - val_accuracy: 0.4635 - val_loss: 1.9394 - learning_rate: 5.0000e-04\nEpoch 15/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697ms/step - accuracy: 0.5087 - loss: 1.7894\nEpoch 15: val_accuracy did not improve from 0.46445\n\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 701ms/step - accuracy: 0.5087 - loss: 1.7893 - val_accuracy: 0.4102 - val_loss: 2.0963 - learning_rate: 5.0000e-04\nEpoch 16/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693ms/step - accuracy: 0.5215 - loss: 1.7016\nEpoch 16: val_accuracy did not improve from 0.46445\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 697ms/step - accuracy: 0.5215 - loss: 1.7014 - val_accuracy: 0.4621 - val_loss: 1.8367 - learning_rate: 2.5000e-04\nEpoch 17/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686ms/step - accuracy: 0.5369 - loss: 1.6370\nEpoch 17: val_accuracy did not improve from 0.46445\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 690ms/step - accuracy: 0.5369 - loss: 1.6371 - val_accuracy: 0.4186 - val_loss: 1.9744 - learning_rate: 2.5000e-04\nEpoch 18/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696ms/step - accuracy: 0.5304 - loss: 1.6412\nEpoch 18: val_accuracy did not improve from 0.46445\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 700ms/step - accuracy: 0.5304 - loss: 1.6412 - val_accuracy: 0.4443 - val_loss: 1.8812 - learning_rate: 2.5000e-04\nEpoch 19/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703ms/step - accuracy: 0.5425 - loss: 1.6293\nEpoch 19: val_accuracy improved from 0.46445 to 0.48597, saving model to model.keras\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 800ms/step - accuracy: 0.5424 - loss: 1.6294 - val_accuracy: 0.4860 - val_loss: 1.7866 - learning_rate: 2.5000e-04\nEpoch 20/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5486 - loss: 1.6151\nEpoch 20: val_accuracy improved from 0.48597 to 0.52245, saving model to model.keras\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 1s/step - accuracy: 0.5486 - loss: 1.6152 - val_accuracy: 0.5225 - val_loss: 1.6758 - learning_rate: 2.5000e-04\nEpoch 21/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5476 - loss: 1.6024\nEpoch 21: val_accuracy did not improve from 0.52245\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 2s/step - accuracy: 0.5476 - loss: 1.6025 - val_accuracy: 0.4747 - val_loss: 1.8168 - learning_rate: 2.5000e-04\nEpoch 22/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763ms/step - accuracy: 0.5533 - loss: 1.6018\nEpoch 22: val_accuracy did not improve from 0.52245\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 767ms/step - accuracy: 0.5533 - loss: 1.6019 - val_accuracy: 0.4238 - val_loss: 1.9394 - learning_rate: 2.5000e-04\nEpoch 23/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691ms/step - accuracy: 0.5489 - loss: 1.6131\nEpoch 23: val_accuracy did not improve from 0.52245\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 695ms/step - accuracy: 0.5489 - loss: 1.6132 - val_accuracy: 0.5117 - val_loss: 1.7306 - learning_rate: 2.5000e-04\nEpoch 24/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688ms/step - accuracy: 0.5539 - loss: 1.5770\nEpoch 24: val_accuracy did not improve from 0.52245\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 692ms/step - accuracy: 0.5539 - loss: 1.5771 - val_accuracy: 0.4298 - val_loss: 1.9262 - learning_rate: 2.5000e-04\nEpoch 25/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688ms/step - accuracy: 0.5493 - loss: 1.6049\nEpoch 25: val_accuracy did not improve from 0.52245\n\nEpoch 25: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 692ms/step - accuracy: 0.5493 - loss: 1.6050 - val_accuracy: 0.4972 - val_loss: 1.7332 - learning_rate: 2.5000e-04\nEpoch 26/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.5640 - loss: 1.5432\nEpoch 26: val_accuracy did not improve from 0.52245\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 715ms/step - accuracy: 0.5640 - loss: 1.5431 - val_accuracy: 0.5150 - val_loss: 1.6514 - learning_rate: 1.2500e-04\nEpoch 27/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696ms/step - accuracy: 0.5739 - loss: 1.4879\nEpoch 27: val_accuracy did not improve from 0.52245\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 700ms/step - accuracy: 0.5739 - loss: 1.4879 - val_accuracy: 0.5117 - val_loss: 1.7159 - learning_rate: 1.2500e-04\nEpoch 28/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686ms/step - accuracy: 0.5702 - loss: 1.4796\nEpoch 28: val_accuracy improved from 0.52245 to 0.53601, saving model to model.keras\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 782ms/step - accuracy: 0.5702 - loss: 1.4797 - val_accuracy: 0.5360 - val_loss: 1.6051 - learning_rate: 1.2500e-04\nEpoch 29/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796ms/step - accuracy: 0.5792 - loss: 1.4719\nEpoch 29: val_accuracy did not improve from 0.53601\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 800ms/step - accuracy: 0.5792 - loss: 1.4720 - val_accuracy: 0.5084 - val_loss: 1.7092 - learning_rate: 1.2500e-04\nEpoch 30/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698ms/step - accuracy: 0.5855 - loss: 1.4590\nEpoch 30: val_accuracy did not improve from 0.53601\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 702ms/step - accuracy: 0.5854 - loss: 1.4591 - val_accuracy: 0.5210 - val_loss: 1.6608 - learning_rate: 1.2500e-04\nEpoch 31/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684ms/step - accuracy: 0.5800 - loss: 1.4625\nEpoch 31: val_accuracy improved from 0.53601 to 0.55706, saving model to model.keras\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 779ms/step - accuracy: 0.5800 - loss: 1.4625 - val_accuracy: 0.5571 - val_loss: 1.5603 - learning_rate: 1.2500e-04\nEpoch 32/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5880 - loss: 1.4471\nEpoch 32: val_accuracy did not improve from 0.55706\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 1s/step - accuracy: 0.5879 - loss: 1.4472 - val_accuracy: 0.5407 - val_loss: 1.6085 - learning_rate: 1.2500e-04\nEpoch 33/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940ms/step - accuracy: 0.5869 - loss: 1.4353\nEpoch 33: val_accuracy improved from 0.55706 to 0.56876, saving model to model.keras\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 1s/step - accuracy: 0.5869 - loss: 1.4354 - val_accuracy: 0.5688 - val_loss: 1.5396 - learning_rate: 1.2500e-04\nEpoch 34/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5864 - loss: 1.4527\nEpoch 34: val_accuracy did not improve from 0.56876\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 2s/step - accuracy: 0.5864 - loss: 1.4527 - val_accuracy: 0.5407 - val_loss: 1.5853 - learning_rate: 1.2500e-04\nEpoch 35/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759ms/step - accuracy: 0.5893 - loss: 1.4311\nEpoch 35: val_accuracy did not improve from 0.56876\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 763ms/step - accuracy: 0.5893 - loss: 1.4311 - val_accuracy: 0.5627 - val_loss: 1.5236 - learning_rate: 1.2500e-04\nEpoch 36/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695ms/step - accuracy: 0.5945 - loss: 1.4349\nEpoch 36: val_accuracy did not improve from 0.56876\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 699ms/step - accuracy: 0.5945 - loss: 1.4349 - val_accuracy: 0.5374 - val_loss: 1.5802 - learning_rate: 1.2500e-04\nEpoch 37/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689ms/step - accuracy: 0.5901 - loss: 1.4194\nEpoch 37: val_accuracy did not improve from 0.56876\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 693ms/step - accuracy: 0.5901 - loss: 1.4195 - val_accuracy: 0.5262 - val_loss: 1.6047 - learning_rate: 1.2500e-04\nEpoch 38/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705ms/step - accuracy: 0.5951 - loss: 1.4265\nEpoch 38: val_accuracy did not improve from 0.56876\n\nEpoch 38: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 709ms/step - accuracy: 0.5951 - loss: 1.4265 - val_accuracy: 0.5346 - val_loss: 1.6236 - learning_rate: 1.2500e-04\nEpoch 39/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698ms/step - accuracy: 0.6037 - loss: 1.3804\nEpoch 39: val_accuracy improved from 0.56876 to 0.57203, saving model to model.keras\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 793ms/step - accuracy: 0.6037 - loss: 1.3804 - val_accuracy: 0.5720 - val_loss: 1.4644 - learning_rate: 6.2500e-05\nEpoch 40/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6083 - loss: 1.3521\nEpoch 40: val_accuracy did not improve from 0.57203\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 2s/step - accuracy: 0.6083 - loss: 1.3520 - val_accuracy: 0.5692 - val_loss: 1.5089 - learning_rate: 6.2500e-05\nEpoch 41/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752ms/step - accuracy: 0.6216 - loss: 1.3180\nEpoch 41: val_accuracy improved from 0.57203 to 0.57764, saving model to model.keras\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 845ms/step - accuracy: 0.6216 - loss: 1.3181 - val_accuracy: 0.5776 - val_loss: 1.4480 - learning_rate: 6.2500e-05\nEpoch 42/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6183 - loss: 1.3283\nEpoch 42: val_accuracy did not improve from 0.57764\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 2s/step - accuracy: 0.6183 - loss: 1.3283 - val_accuracy: 0.5454 - val_loss: 1.5475 - learning_rate: 6.2500e-05\nEpoch 43/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767ms/step - accuracy: 0.6291 - loss: 1.2926\nEpoch 43: val_accuracy did not improve from 0.57764\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 771ms/step - accuracy: 0.6291 - loss: 1.2927 - val_accuracy: 0.5566 - val_loss: 1.5231 - learning_rate: 6.2500e-05\nEpoch 44/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726ms/step - accuracy: 0.6277 - loss: 1.2920\nEpoch 44: val_accuracy did not improve from 0.57764\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 730ms/step - accuracy: 0.6276 - loss: 1.2920 - val_accuracy: 0.5627 - val_loss: 1.5076 - learning_rate: 6.2500e-05\nEpoch 45/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725ms/step - accuracy: 0.6275 - loss: 1.2954\nEpoch 45: val_accuracy improved from 0.57764 to 0.58232, saving model to model.keras\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 820ms/step - accuracy: 0.6275 - loss: 1.2955 - val_accuracy: 0.5823 - val_loss: 1.4419 - learning_rate: 6.2500e-05\nEpoch 46/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6307 - loss: 1.2951\nEpoch 46: val_accuracy did not improve from 0.58232\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 1s/step - accuracy: 0.6307 - loss: 1.2951 - val_accuracy: 0.5795 - val_loss: 1.4342 - learning_rate: 6.2500e-05\nEpoch 47/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767ms/step - accuracy: 0.6239 - loss: 1.2968\nEpoch 47: val_accuracy did not improve from 0.58232\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 771ms/step - accuracy: 0.6239 - loss: 1.2968 - val_accuracy: 0.5636 - val_loss: 1.4946 - learning_rate: 6.2500e-05\nEpoch 48/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744ms/step - accuracy: 0.6345 - loss: 1.2751\nEpoch 48: val_accuracy did not improve from 0.58232\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 748ms/step - accuracy: 0.6345 - loss: 1.2751 - val_accuracy: 0.5706 - val_loss: 1.4935 - learning_rate: 6.2500e-05\nEpoch 49/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732ms/step - accuracy: 0.6387 - loss: 1.2624\nEpoch 49: val_accuracy did not improve from 0.58232\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 737ms/step - accuracy: 0.6387 - loss: 1.2625 - val_accuracy: 0.5748 - val_loss: 1.4858 - learning_rate: 6.2500e-05\nEpoch 50/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724ms/step - accuracy: 0.6370 - loss: 1.2682\nEpoch 50: val_accuracy did not improve from 0.58232\n\nEpoch 50: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 728ms/step - accuracy: 0.6370 - loss: 1.2683 - val_accuracy: 0.5594 - val_loss: 1.5022 - learning_rate: 6.2500e-05\nEpoch 51/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740ms/step - accuracy: 0.6472 - loss: 1.2248\nEpoch 51: val_accuracy improved from 0.58232 to 0.60851, saving model to model.keras\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 832ms/step - accuracy: 0.6472 - loss: 1.2249 - val_accuracy: 0.6085 - val_loss: 1.3692 - learning_rate: 3.1250e-05\nEpoch 52/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718ms/step - accuracy: 0.6584 - loss: 1.2033\nEpoch 52: val_accuracy improved from 0.60851 to 0.61272, saving model to model.keras\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 809ms/step - accuracy: 0.6584 - loss: 1.2033 - val_accuracy: 0.6127 - val_loss: 1.3540 - learning_rate: 3.1250e-05\nEpoch 53/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707ms/step - accuracy: 0.6555 - loss: 1.2085\nEpoch 53: val_accuracy improved from 0.61272 to 0.62395, saving model to model.keras\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 798ms/step - accuracy: 0.6555 - loss: 1.2085 - val_accuracy: 0.6239 - val_loss: 1.3254 - learning_rate: 3.1250e-05\nEpoch 54/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681ms/step - accuracy: 0.6599 - loss: 1.1991\nEpoch 54: val_accuracy improved from 0.62395 to 0.63237, saving model to model.keras\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 773ms/step - accuracy: 0.6599 - loss: 1.1991 - val_accuracy: 0.6324 - val_loss: 1.3134 - learning_rate: 3.1250e-05\nEpoch 55/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705ms/step - accuracy: 0.6618 - loss: 1.1914\nEpoch 55: val_accuracy did not improve from 0.63237\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 709ms/step - accuracy: 0.6618 - loss: 1.1914 - val_accuracy: 0.6066 - val_loss: 1.3649 - learning_rate: 3.1250e-05\nEpoch 56/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734ms/step - accuracy: 0.6741 - loss: 1.1643\nEpoch 56: val_accuracy did not improve from 0.63237\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 738ms/step - accuracy: 0.6740 - loss: 1.1644 - val_accuracy: 0.6179 - val_loss: 1.3450 - learning_rate: 3.1250e-05\nEpoch 57/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747ms/step - accuracy: 0.6688 - loss: 1.1648\nEpoch 57: val_accuracy did not improve from 0.63237\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 751ms/step - accuracy: 0.6687 - loss: 1.1649 - val_accuracy: 0.5978 - val_loss: 1.3970 - learning_rate: 3.1250e-05\nEpoch 58/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735ms/step - accuracy: 0.6644 - loss: 1.1739\nEpoch 58: val_accuracy did not improve from 0.63237\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 739ms/step - accuracy: 0.6645 - loss: 1.1738 - val_accuracy: 0.6010 - val_loss: 1.3696 - learning_rate: 3.1250e-05\nEpoch 59/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727ms/step - accuracy: 0.6737 - loss: 1.1543\nEpoch 59: val_accuracy did not improve from 0.63237\n\nEpoch 59: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 732ms/step - accuracy: 0.6737 - loss: 1.1543 - val_accuracy: 0.6085 - val_loss: 1.3554 - learning_rate: 3.1250e-05\nEpoch 60/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730ms/step - accuracy: 0.6840 - loss: 1.1382\nEpoch 60: val_accuracy improved from 0.63237 to 0.63424, saving model to model.keras\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 822ms/step - accuracy: 0.6840 - loss: 1.1382 - val_accuracy: 0.6342 - val_loss: 1.2901 - learning_rate: 1.5625e-05\nEpoch 61/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668ms/step - accuracy: 0.6830 - loss: 1.1132\nEpoch 61: val_accuracy did not improve from 0.63424\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 672ms/step - accuracy: 0.6830 - loss: 1.1132 - val_accuracy: 0.6300 - val_loss: 1.3126 - learning_rate: 1.5625e-05\nEpoch 62/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721ms/step - accuracy: 0.6842 - loss: 1.1166\nEpoch 62: val_accuracy did not improve from 0.63424\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 725ms/step - accuracy: 0.6842 - loss: 1.1165 - val_accuracy: 0.6071 - val_loss: 1.3456 - learning_rate: 1.5625e-05\nEpoch 63/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722ms/step - accuracy: 0.6869 - loss: 1.1116\nEpoch 63: val_accuracy did not improve from 0.63424\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 726ms/step - accuracy: 0.6869 - loss: 1.1116 - val_accuracy: 0.6239 - val_loss: 1.3171 - learning_rate: 1.5625e-05\nEpoch 64/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727ms/step - accuracy: 0.6896 - loss: 1.1066\nEpoch 64: val_accuracy did not improve from 0.63424\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 731ms/step - accuracy: 0.6896 - loss: 1.1066 - val_accuracy: 0.6314 - val_loss: 1.2890 - learning_rate: 1.5625e-05\nEpoch 65/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718ms/step - accuracy: 0.6927 - loss: 1.1049\nEpoch 65: val_accuracy did not improve from 0.63424\n\nEpoch 65: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 722ms/step - accuracy: 0.6927 - loss: 1.1048 - val_accuracy: 0.6169 - val_loss: 1.3214 - learning_rate: 1.5625e-05\nEpoch 66/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715ms/step - accuracy: 0.7005 - loss: 1.0775\nEpoch 66: val_accuracy improved from 0.63424 to 0.64079, saving model to model.keras\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 808ms/step - accuracy: 0.7005 - loss: 1.0775 - val_accuracy: 0.6408 - val_loss: 1.2647 - learning_rate: 7.8125e-06\nEpoch 67/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654ms/step - accuracy: 0.6984 - loss: 1.0730\nEpoch 67: val_accuracy improved from 0.64079 to 0.64546, saving model to model.keras\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 747ms/step - accuracy: 0.6984 - loss: 1.0730 - val_accuracy: 0.6455 - val_loss: 1.2601 - learning_rate: 7.8125e-06\nEpoch 68/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7060 - loss: 1.0628\nEpoch 68: val_accuracy did not improve from 0.64546\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.7060 - loss: 1.0628 - val_accuracy: 0.6422 - val_loss: 1.2628 - learning_rate: 7.8125e-06\nEpoch 69/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750ms/step - accuracy: 0.7053 - loss: 1.0532\nEpoch 69: val_accuracy did not improve from 0.64546\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 754ms/step - accuracy: 0.7053 - loss: 1.0532 - val_accuracy: 0.6310 - val_loss: 1.2761 - learning_rate: 7.8125e-06\nEpoch 70/100\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715ms/step - accuracy: 0.7096 - loss: 1.0520\nEpoch 70: val_accuracy did not improve from 0.64546\n\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 719ms/step - accuracy: 0.7095 - loss: 1.0521 - val_accuracy: 0.6370 - val_loss: 1.2805 - learning_rate: 7.8125e-06\nEpoch 71/100\n\u001b[1m 97/151\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 739ms/step - accuracy: 0.7046 - loss: 1.0603","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"#### Validation\nCompute validation metrics.","metadata":{"editable":true,"id":"8IMMO_mT-AM9","slideshow":{"slide_type":""},"tags":[]}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef draw_confusion_matrix(cm, categories):\n    # Draw confusion matrix\n    fig = plt.figure(figsize=[6.4*pow(len(categories), 0.5), 4.8*pow(len(categories), 0.5)])\n    ax = fig.add_subplot(111)\n    cm = cm.astype('float') / np.maximum(cm.sum(axis=1)[:, np.newaxis], np.finfo(np.float64).eps)\n    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.get_cmap('Blues'))\n    ax.figure.colorbar(im, ax=ax)\n    ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), xticklabels=list(categories.values()), yticklabels=list(categories.values()), ylabel='Annotation', xlabel='Prediction')\n    # Rotate the tick labels and set their alignment\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n    # Loop over data dimensions and create text annotations\n    thresh = cm.max() / 2.0\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], '.2f'), ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\", fontsize=int(20-pow(len(categories), 0.5)))\n    fig.tight_layout()\n    plt.show(fig)","metadata":{"id":"HAanJ-V0-AM1","trusted":true,"execution":{"execution_failed":"2025-03-03T17:42:50.403Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nmodel.load_weights('/kaggle/working/model.keras')\ny_true, y_pred = [], []\nfor ann in anns_valid:\n    # Load image\n    image = load_geoimage(ann.filename)\n    for obj_pred in ann.objects:\n        # Generate prediction\n        warped_image = np.expand_dims(image, 0)\n        predictions = model.predict(warped_image, verbose=0)\n        # Save prediction\n        pred_category = list(categories.values())[np.argmax(predictions)]\n        pred_score = np.max(predictions)\n        y_true.append(obj_pred.category)\n        y_pred.append(pred_category)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-03T17:42:50.403Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\n# Compute the confusion matrix\ncm = confusion_matrix(y_true, y_pred, labels=list(categories.values()))\ndraw_confusion_matrix(cm, categories)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-03T17:42:50.403Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n# Compute the accuracy\ncorrect_samples_class = np.diag(cm).astype(float)\ntotal_samples_class = np.sum(cm, axis=1).astype(float)\ntotal_predicts_class = np.sum(cm, axis=0).astype(float)\nprint('Mean Accuracy: %.3f%%' % (np.sum(correct_samples_class) / np.sum(total_samples_class) * 100))\nacc = correct_samples_class / np.maximum(total_samples_class, np.finfo(np.float64).eps)\nprint('Mean Recall: %.3f%%' % (acc.mean() * 100))\nacc = correct_samples_class / np.maximum(total_predicts_class, np.finfo(np.float64).eps)\nprint('Mean Precision: %.3f%%' % (acc.mean() * 100))\nfor idx in range(len(categories)):\n    # True/False Positives (TP/FP) refer to the number of predicted positives that were correct/incorrect.\n    # True/False Negatives (TN/FN) refer to the number of predicted negatives that were correct/incorrect.\n    tp = cm[idx, idx]\n    fp = sum(cm[:, idx]) - tp\n    fn = sum(cm[idx, :]) - tp\n    tn = sum(np.delete(sum(cm) - cm[idx, :], idx))\n    # True Positive Rate: proportion of real positive cases that were correctly predicted as positive.\n    recall = tp / np.maximum(tp+fn, np.finfo(np.float64).eps)\n    # Precision: proportion of predicted positive cases that were truly real positives.\n    precision = tp / np.maximum(tp+fp, np.finfo(np.float64).eps)\n    # True Negative Rate: proportion of real negative cases that were correctly predicted as negative.\n    specificity = tn / np.maximum(tn+fp, np.finfo(np.float64).eps)\n    # Dice coefficient refers to two times the intersection of two sets divided by the sum of their areas.\n    # Dice = 2 |A∩B| / (|A|+|B|) = 2 TP / (2 TP + FP + FN)\n    f1_score = 2 * ((precision * recall) / np.maximum(precision+recall, np.finfo(np.float64).eps))\n    print('> %s: Recall: %.3f%% Precision: %.3f%% Specificity: %.3f%% Dice: %.3f%%' % (list(categories.values())[idx], recall*100, precision*100, specificity*100, f1_score*100))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-03T17:42:50.404Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Testing\nTry to improve the results provided in the competition.","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\n\nanns = []\nfor (dirpath, dirnames, filenames) in os.walk('../input/xview-recognition/xview_recognition/xview_test'):\n    for filename in filenames:\n        image_path = os.path.relpath(os.path.join(dirpath, filename), '../input/xview-recognition/xview_recognition/')\n        image = GenericImage(image_path)\n        image.tile = np.array([0, 0, 224, 224])\n        obj = GenericObject()\n        obj.bb = (0, 0, 224, 224)\n        obj.category = dirpath[dirpath.rfind('/')+1:]\n        image.add_object(obj)\n        anns.append(image)\nprint('Number of testing images: ' + str(len(anns)))","metadata":{"id":"tJr_-xCt-AM-","trusted":true,"execution":{"execution_failed":"2025-03-03T17:42:50.404Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nmodel.load_weights('/kaggle/working/model.keras')\npredictions_data = {\"images\": {}, \"annotations\": {}}\nfor idx, ann in enumerate(anns):\n    image_data = {\"image_id\": ann.filename.split('/')[-1], \"filename\": ann.filename, \"width\": int(ann.tile[2]), \"height\": int(ann.tile[3])}\n    predictions_data[\"images\"][idx] = image_data\n    # Load image\n    image = load_geoimage(ann.filename)\n    for obj_pred in ann.objects:\n        # Generate prediction\n        warped_image = np.expand_dims(image, 0)\n        predictions = model.predict(warped_image, verbose=0)\n        # Save prediction\n        pred_category = list(categories.values())[np.argmax(predictions)]\n        pred_score = np.max(predictions)\n        annotation_data = {\"image_id\": ann.filename.split('/')[-1], \"category_id\": pred_category, \"bbox\": [int(x) for x in obj_pred.bb]}\n        predictions_data[\"annotations\"][idx] = annotation_data","metadata":{"id":"TGs2zqfv-AM_","trusted":true,"execution":{"execution_failed":"2025-03-03T17:42:50.404Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"/kaggle/working/prediction.json\", \"w\") as outfile:\n    json.dump(predictions_data, outfile)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-03T17:42:50.404Z"}},"outputs":[],"execution_count":null}]}