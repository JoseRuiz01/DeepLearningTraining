{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "QYuALZOG-AMq",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Assignment: Image recognition\n",
    "- Alumno 1: José Antonio Ruiz Heredia\n",
    "- Alumno 2: Álvaro Honrubia\n",
    "- Alumno 3: Hector Carlos Flores Reynoso \n",
    "\n",
    "The goals of the assignment are:\n",
    "* Develop proficiency in using Tensorflow/Keras for training Neural Nets (NNs).\n",
    "* Put into practice the acquired knowledge to optimize the parameters and architecture of a feedforward Neural Net (ffNN), in the context of an image recognition problem.\n",
    "* Put into practice NNs specially conceived for analysing images. Design and optimize the parameters of a Convolutional Neural Net (CNN) to deal with previous task.\n",
    "* Train popular architectures from scratch (e.g., GoogLeNet, VGG, ResNet, ...), and compare the results with the ones provided by their pre-trained versions using transfer learning.\n",
    "\n",
    "Follow the link below to download the classification data set  “xview_recognition”: [https://drive.upm.es/s/4oNHlRFEd71HXp4](https://drive.upm.es/s/4oNHlRFEd71HXp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T00:00:21.031186Z",
     "start_time": "2024-10-26T00:00:17.131476Z"
    },
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-02-28T08:03:58.450466Z",
     "iopub.status.busy": "2025-02-28T08:03:58.450212Z",
     "iopub.status.idle": "2025-02-28T08:04:11.511749Z",
     "shell.execute_reply": "2025-02-28T08:04:11.510981Z",
     "shell.execute_reply.started": "2025-02-28T08:03:58.450437Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T00:00:21.066937Z",
     "start_time": "2024-10-26T00:00:21.059126Z"
    },
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-02-28T08:04:11.513096Z",
     "iopub.status.busy": "2025-02-28T08:04:11.512521Z",
     "iopub.status.idle": "2025-02-28T08:04:11.518470Z",
     "shell.execute_reply": "2025-02-28T08:04:11.517682Z",
     "shell.execute_reply.started": "2025-02-28T08:04:11.513070Z"
    },
    "id": "OYtqD3Oh-AMw",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "import numpy as np\n",
    "\n",
    "class GenericObject:\n",
    "    \"\"\"\n",
    "    Generic object data.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.id = uuid.uuid4()\n",
    "        self.bb = (-1, -1, -1, -1)\n",
    "        self.category= -1\n",
    "        self.score = -1\n",
    "\n",
    "class GenericImage:\n",
    "    \"\"\"\n",
    "    Generic image data.\n",
    "    \"\"\"\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.tile = np.array([-1, -1, -1, -1])  # (pt_x, pt_y, pt_x+width, pt_y+height)\n",
    "        self.objects = list([])\n",
    "\n",
    "    def add_object(self, obj: GenericObject):\n",
    "        self.objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T00:00:21.153693Z",
     "start_time": "2024-10-26T00:00:21.149079Z"
    },
    "execution": {
     "iopub.execute_input": "2025-02-28T08:04:11.519794Z",
     "iopub.status.busy": "2025-02-28T08:04:11.519374Z",
     "iopub.status.idle": "2025-02-28T08:04:11.549152Z",
     "shell.execute_reply": "2025-02-28T08:04:11.548419Z",
     "shell.execute_reply.started": "2025-02-28T08:04:11.519762Z"
    },
    "id": "I_GygShu-AMz",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "categories = {0: 'Cargo plane', 1: 'Helicopter', 2: 'Small car', 3: 'Bus', 4: 'Truck', 5: 'Motorboat', 6: 'Fishing vessel', 7: 'Dump truck', 8: 'Excavator', 9: 'Building', 10: 'Storage tank', 11: 'Shipping container'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T08:04:11.551064Z",
     "iopub.status.busy": "2025-02-28T08:04:11.550870Z",
     "iopub.status.idle": "2025-02-28T08:04:16.925778Z",
     "shell.execute_reply": "2025-02-28T08:04:16.924746Z",
     "shell.execute_reply.started": "2025-02-28T08:04:11.551045Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rasterio\n",
      "  Downloading rasterio-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting affine (from rasterio)\n",
      "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (25.1.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2025.1.31)\n",
      "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
      "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
      "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.26.4)\n",
      "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from rasterio) (3.2.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24->rasterio) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24->rasterio) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.24->rasterio) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.24->rasterio) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.24->rasterio) (2024.2.0)\n",
      "Downloading rasterio-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: affine, rasterio\n",
      "Successfully installed affine-2.4.0 rasterio-1.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T00:00:21.292654Z",
     "start_time": "2024-10-26T00:00:21.205321Z"
    },
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-02-28T08:04:16.927561Z",
     "iopub.status.busy": "2025-02-28T08:04:16.927312Z",
     "iopub.status.idle": "2025-02-28T08:04:17.506662Z",
     "shell.execute_reply": "2025-02-28T08:04:17.505823Z",
     "shell.execute_reply.started": "2025-02-28T08:04:16.927539Z"
    },
    "id": "fRBA7ReQ-AM0",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "def load_geoimage(filename):\n",
    "    warnings.filterwarnings('ignore', category=rasterio.errors.NotGeoreferencedWarning)\n",
    "    src_raster = rasterio.open('../input/xview-dataset/xview_recognition/'+filename, 'r')\n",
    "    # RasterIO to OpenCV (see inconsistencies between libjpeg and libjpeg-turbo)\n",
    "    input_type = src_raster.profile['dtype']\n",
    "    input_channels = src_raster.count\n",
    "    img = np.zeros((src_raster.height, src_raster.width, src_raster.count), dtype=input_type)\n",
    "    for band in range(input_channels):\n",
    "        img[:, :, band] = src_raster.read(band+1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diNBB3qy-AM2"
   },
   "source": [
    "#### Training\n",
    "Design and train a ffNN to deal with the “xview_recognition” classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T00:00:21.416449Z",
     "start_time": "2024-10-26T00:00:21.311510Z"
    },
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-02-28T08:04:17.507910Z",
     "iopub.status.busy": "2025-02-28T08:04:17.507420Z",
     "iopub.status.idle": "2025-02-28T08:04:17.616376Z",
     "shell.execute_reply": "2025-02-28T08:04:17.615748Z",
     "shell.execute_reply.started": "2025-02-28T08:04:17.507878Z"
    },
    "id": "Orto292C-AM3",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load database\n",
    "json_file = '../input/xview-dataset/xview_recognition/xview_ann_train.json'\n",
    "with open(json_file) as ifs:\n",
    "    json_data = json.load(ifs)\n",
    "ifs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T00:00:22.874518Z",
     "start_time": "2024-10-26T00:00:22.204948Z"
    },
    "execution": {
     "iopub.execute_input": "2025-02-28T08:04:17.617563Z",
     "iopub.status.busy": "2025-02-28T08:04:17.617264Z",
     "iopub.status.idle": "2025-02-28T08:04:17.995024Z",
     "shell.execute_reply": "2025-02-28T08:04:17.994305Z",
     "shell.execute_reply.started": "2025-02-28T08:04:17.617532Z"
    },
    "id": "4GjFLHs4-AM4",
    "outputId": "5581df22-d4e9-42ac-9f94-061fd8c7acd9",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cargo plane': 635, 'Helicopter': 70, 'Small car': 4290, 'Bus': 2155, 'Truck': 2746, 'Motorboat': 1069, 'Fishing vessel': 706, 'Dump truck': 1236, 'Excavator': 789, 'Building': 4689, 'Storage tank': 1469, 'Shipping container': 1523}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "counts = dict.fromkeys(categories.values(), 0)\n",
    "anns = []\n",
    "for json_img, json_ann in zip(json_data['images'].values(), json_data['annotations'].values()):\n",
    "    image = GenericImage(json_img['filename'])\n",
    "    image.tile = np.array([0, 0, json_img['width'], json_img['height']])\n",
    "    obj = GenericObject()\n",
    "    obj.bb = (int(json_ann['bbox'][0]), int(json_ann['bbox'][1]), int(json_ann['bbox'][2]), int(json_ann['bbox'][3]))\n",
    "    obj.category = json_ann['category_id']\n",
    "    # Resampling strategy to reduce training time\n",
    "    counts[obj.category] += 1\n",
    "    image.add_object(obj)\n",
    "    anns.append(image)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T00:00:23.656800Z",
     "start_time": "2024-10-26T00:00:23.123245Z"
    },
    "execution": {
     "iopub.execute_input": "2025-02-28T08:04:17.995974Z",
     "iopub.status.busy": "2025-02-28T08:04:17.995753Z",
     "iopub.status.idle": "2025-02-28T08:04:18.416546Z",
     "shell.execute_reply": "2025-02-28T08:04:18.415865Z",
     "shell.execute_reply.started": "2025-02-28T08:04:17.995955Z"
    },
    "id": "NriAECvS-AM6",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 19239\n",
      "Number of validation images: 2138\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "anns_train, anns_valid = train_test_split(anns, test_size=0.1, random_state=1, shuffle=True)\n",
    "print('Number of training images: ' + str(len(anns_train)))\n",
    "print('Number of validation images: ' + str(len(anns_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T00:00:25.056806Z",
     "start_time": "2024-10-26T00:00:24.261581Z"
    },
    "execution": {
     "iopub.execute_input": "2025-02-28T08:04:18.417866Z",
     "iopub.status.busy": "2025-02-28T08:04:18.417327Z",
     "iopub.status.idle": "2025-02-28T08:04:20.245826Z",
     "shell.execute_reply": "2025-02-28T08:04:20.245160Z",
     "shell.execute_reply.started": "2025-02-28T08:04:18.417839Z"
    },
    "id": "BNkjbY2e-AM7",
    "outputId": "47bde031-306f-464e-8e22-cc70a7fb7c67",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150528</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │     <span style=\"color: #00af00; text-decoration-color: #00af00\">154,141,696</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,548</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150528\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │     \u001b[38;5;34m154,141,696\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │           \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m524,800\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │           \u001b[38;5;34m1,548\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">154,839,948</span> (590.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m154,839,948\u001b[0m (590.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">154,836,108</span> (590.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m154,836,108\u001b[0m (590.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,840</span> (15.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,840\u001b[0m (15.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load architecture\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "\n",
    "print('Load model')\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(Flatten(input_shape=(224, 224, 3)))\n",
    "\n",
    "# Hidden Layer 1\n",
    "model.add(Dense(units=1024, kernel_initializer=HeNormal()))\n",
    "model.add(LeakyReLU(alpha=0.01)) \n",
    "\n",
    "\n",
    "# Hidden Layer 2\n",
    "model.add(Dense(units=512, kernel_initializer=HeNormal()))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "          \n",
    "# Hidden Layer 3\n",
    "model.add(Dense(units=256, kernel_initializer=HeNormal()))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "          \n",
    "# Hidden Layer 4\n",
    "model.add(Dense(units=128, kernel_initializer=HeNormal()))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(len(categories), activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T00:00:25.467525Z",
     "start_time": "2024-10-26T00:00:25.434068Z"
    },
    "execution": {
     "iopub.execute_input": "2025-02-28T08:04:20.247033Z",
     "iopub.status.busy": "2025-02-28T08:04:20.246724Z",
     "iopub.status.idle": "2025-02-28T08:04:20.261010Z",
     "shell.execute_reply": "2025-02-28T08:04:20.260316Z",
     "shell.execute_reply.started": "2025-02-28T08:04:20.247001Z"
    },
    "id": "-aSlKtG6-AM7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "## Learning rate is changed (0.0001)\n",
    "## beta 1: controls the exponential decay rate for the 1st moment (0.8)\n",
    "## beta 2: controls the 2nd moment decay, fine-tuned for specific tasks. (0.999)\n",
    "## epsilon: avoid numerical instability (1e-9)\n",
    "\n",
    "opt = Adam(learning_rate=5e-4, beta_1=0.8, beta_2=0.999, epsilon=1e-9, amsgrad=True, clipnorm=1.0)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T00:00:26.254555Z",
     "start_time": "2024-10-26T00:00:26.243908Z"
    },
    "execution": {
     "iopub.execute_input": "2025-02-28T08:04:20.262134Z",
     "iopub.status.busy": "2025-02-28T08:04:20.261869Z",
     "iopub.status.idle": "2025-02-28T08:04:20.277420Z",
     "shell.execute_reply": "2025-02-28T08:04:20.276769Z",
     "shell.execute_reply.started": "2025-02-28T08:04:20.262106Z"
    },
    "id": "GGAJEfpB-AM8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TerminateOnNaN, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# Callbacks\n",
    "model_checkpoint = ModelCheckpoint('model.keras', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "## Change the factor to 0.5 and patience to 5 to make the learning rate decrease.\n",
    "reduce_lr = ReduceLROnPlateau('val_accuracy', factor=0.5, patience=5, verbose=1)\n",
    "## Reduce the patience to stop early if the model doesn’t improve\n",
    "early_stop = EarlyStopping('val_accuracy', patience=10, verbose=1)\n",
    "terminate = TerminateOnNaN()\n",
    "callbacks = [model_checkpoint, reduce_lr, early_stop, terminate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T08:04:20.278426Z",
     "iopub.status.busy": "2025-02-28T08:04:20.278150Z",
     "iopub.status.idle": "2025-02-28T08:04:20.289623Z",
     "shell.execute_reply": "2025-02-28T08:04:20.288915Z",
     "shell.execute_reply.started": "2025-02-28T08:04:20.278399Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generator_images(objs, batch_size, do_shuffle=False):\n",
    "    while True:\n",
    "        if do_shuffle:\n",
    "            np.random.shuffle(objs)\n",
    "        groups = [objs[i:i+batch_size] for i in range(0, len(objs), batch_size)]\n",
    "        for group in groups:\n",
    "            images, labels = [], []\n",
    "            for (filename, obj) in group:\n",
    "                # Load image\n",
    "                images.append(load_geoimage(filename))\n",
    "                probabilities = np.zeros(len(categories))\n",
    "                probabilities[list(categories.values()).index(obj.category)] = 1\n",
    "                labels.append(probabilities)\n",
    "            images = np.array(images).astype(np.float32)\n",
    "            labels = np.array(labels).astype(np.float32)\n",
    "            yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T00:00:27.058834Z",
     "start_time": "2024-10-26T00:00:27.022627Z"
    },
    "execution": {
     "iopub.execute_input": "2025-02-28T08:04:20.292454Z",
     "iopub.status.busy": "2025-02-28T08:04:20.292265Z",
     "iopub.status.idle": "2025-02-28T08:04:20.322713Z",
     "shell.execute_reply": "2025-02-28T08:04:20.322041Z",
     "shell.execute_reply.started": "2025-02-28T08:04:20.292437Z"
    },
    "id": "Yht-QqUH-AM8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Generate the list of objects from annotations\n",
    "objs_train = [(ann.filename, obj) for ann in anns_train for obj in ann.objects]\n",
    "objs_valid = [(ann.filename, obj) for ann in anns_valid for obj in ann.objects]\n",
    "# Generators\n",
    "batch_size = 128 ## Increase bach size (128) \n",
    "train_generator = generator_images(objs_train, batch_size, do_shuffle=True)\n",
    "valid_generator = generator_images(objs_valid, batch_size, do_shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-26T00:00:27.913670Z"
    },
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-02-28T08:04:20.323822Z",
     "iopub.status.busy": "2025-02-28T08:04:20.323626Z"
    },
    "id": "TrfpdECs-AM9",
    "jupyter": {
     "is_executing": true
    },
    "outputId": "21d89b78-d94c-442e-9bc2-517654c0b614",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n",
      "Epoch 1/60\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3925 - loss: 1.8436\n",
      "Epoch 1: val_accuracy improved from -inf to 0.36857, saving model to model.keras\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m710s\u001b[0m 5s/step - accuracy: 0.3929 - loss: 1.8421 - val_accuracy: 0.3686 - val_loss: 2.0831 - learning_rate: 5.0000e-04\n",
      "Epoch 2/60\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536ms/step - accuracy: 0.5441 - loss: 1.3365\n",
      "Epoch 2: val_accuracy improved from 0.36857 to 0.48784, saving model to model.keras\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 684ms/step - accuracy: 0.5442 - loss: 1.3365 - val_accuracy: 0.4878 - val_loss: 1.5758 - learning_rate: 5.0000e-04\n",
      "Epoch 3/60\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531ms/step - accuracy: 0.5895 - loss: 1.1908\n",
      "Epoch 3: val_accuracy improved from 0.48784 to 0.49345, saving model to model.keras\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 681ms/step - accuracy: 0.5895 - loss: 1.1909 - val_accuracy: 0.4935 - val_loss: 1.4986 - learning_rate: 5.0000e-04\n",
      "Epoch 4/60\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - accuracy: 0.6141 - loss: 1.1137\n",
      "Epoch 4: val_accuracy did not improve from 0.49345\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 559ms/step - accuracy: 0.6141 - loss: 1.1137 - val_accuracy: 0.4518 - val_loss: 1.7518 - learning_rate: 5.0000e-04\n",
      "Epoch 5/60\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549ms/step - accuracy: 0.6430 - loss: 1.0278\n",
      "Epoch 5: val_accuracy improved from 0.49345 to 0.51543, saving model to model.keras\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 647ms/step - accuracy: 0.6429 - loss: 1.0279 - val_accuracy: 0.5154 - val_loss: 1.4012 - learning_rate: 5.0000e-04\n",
      "Epoch 6/60\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546ms/step - accuracy: 0.6672 - loss: 0.9678\n",
      "Epoch 6: val_accuracy did not improve from 0.51543\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 550ms/step - accuracy: 0.6672 - loss: 0.9678 - val_accuracy: 0.5154 - val_loss: 1.4685 - learning_rate: 5.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572ms/step - accuracy: 0.6946 - loss: 0.8902\n",
      "Epoch 7: val_accuracy did not improve from 0.51543\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 576ms/step - accuracy: 0.6946 - loss: 0.8903 - val_accuracy: 0.4687 - val_loss: 1.7377 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577ms/step - accuracy: 0.7169 - loss: 0.8195\n",
      "Epoch 8: val_accuracy did not improve from 0.51543\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 581ms/step - accuracy: 0.7168 - loss: 0.8196 - val_accuracy: 0.5019 - val_loss: 1.5993 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575ms/step - accuracy: 0.7395 - loss: 0.7646\n",
      "Epoch 9: val_accuracy improved from 0.51543 to 0.53461, saving model to model.keras\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 672ms/step - accuracy: 0.7395 - loss: 0.7647 - val_accuracy: 0.5346 - val_loss: 1.4011 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505ms/step - accuracy: 0.7690 - loss: 0.6966\n",
      "Epoch 10: val_accuracy improved from 0.53461 to 0.54022, saving model to model.keras\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 602ms/step - accuracy: 0.7689 - loss: 0.6967 - val_accuracy: 0.5402 - val_loss: 1.4608 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - accuracy: 0.7724 - loss: 0.6685\n",
      "Epoch 11: val_accuracy did not improve from 0.54022\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 499ms/step - accuracy: 0.7724 - loss: 0.6686 - val_accuracy: 0.5094 - val_loss: 1.6403 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587ms/step - accuracy: 0.8039 - loss: 0.5949\n",
      "Epoch 12: val_accuracy improved from 0.54022 to 0.57671, saving model to model.keras\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 687ms/step - accuracy: 0.8039 - loss: 0.5950 - val_accuracy: 0.5767 - val_loss: 1.3570 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8082 - loss: 0.5631\n",
      "Epoch 13: val_accuracy did not improve from 0.57671\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 1s/step - accuracy: 0.8081 - loss: 0.5631 - val_accuracy: 0.4869 - val_loss: 1.8845 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603ms/step - accuracy: 0.8262 - loss: 0.5198\n",
      "Epoch 14: val_accuracy did not improve from 0.57671\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 607ms/step - accuracy: 0.8262 - loss: 0.5199 - val_accuracy: 0.5496 - val_loss: 1.5546 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.8417 - loss: 0.4721\n",
      "Epoch 15: val_accuracy did not improve from 0.57671\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 568ms/step - accuracy: 0.8417 - loss: 0.4722 - val_accuracy: 0.5346 - val_loss: 1.5682 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559ms/step - accuracy: 0.8572 - loss: 0.4372\n",
      "Epoch 16: val_accuracy did not improve from 0.57671\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 563ms/step - accuracy: 0.8572 - loss: 0.4373 - val_accuracy: 0.5351 - val_loss: 1.7660 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.8710 - loss: 0.3984\n",
      "Epoch 17: val_accuracy did not improve from 0.57671\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 568ms/step - accuracy: 0.8709 - loss: 0.3985 - val_accuracy: 0.5449 - val_loss: 1.6416 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568ms/step - accuracy: 0.9135 - loss: 0.2949\n",
      "Epoch 18: val_accuracy improved from 0.57671 to 0.62488, saving model to model.keras\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 668ms/step - accuracy: 0.9136 - loss: 0.2949 - val_accuracy: 0.6249 - val_loss: 1.2816 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886ms/step - accuracy: 0.9380 - loss: 0.2282\n",
      "Epoch 19: val_accuracy did not improve from 0.62488\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 891ms/step - accuracy: 0.9380 - loss: 0.2282 - val_accuracy: 0.6141 - val_loss: 1.4054 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m120/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m18s\u001b[0m 597ms/step - accuracy: 0.9439 - loss: 0.2098"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "print('Training model')\n",
    "epochs = 60 ## Increase epochs (60) \n",
    "train_steps = math.ceil(len(objs_train)/batch_size)\n",
    "valid_steps = math.ceil(len(objs_valid)/batch_size)\n",
    "h = model.fit(train_generator, steps_per_epoch=train_steps, validation_data=valid_generator, validation_steps=valid_steps, epochs=epochs, callbacks=callbacks, verbose=1)\n",
    "# Best validation model\n",
    "best_idx = int(np.argmax(h.history['val_accuracy']))\n",
    "best_value = np.max(h.history['val_accuracy'])\n",
    "print('Best validation model: epoch ' + str(best_idx+1), ' - val_accuracy ' + str(best_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "8IMMO_mT-AM9",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Validation\n",
    "Compute validation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HAanJ-V0-AM1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def draw_confusion_matrix(cm, categories):\n",
    "    # Draw confusion matrix\n",
    "    fig = plt.figure(figsize=[6.4*pow(len(categories), 0.5), 4.8*pow(len(categories), 0.5)])\n",
    "    ax = fig.add_subplot(111)\n",
    "    cm = cm.astype('float') / np.maximum(cm.sum(axis=1)[:, np.newaxis], np.finfo(np.float64).eps)\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.get_cmap('Blues'))\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), xticklabels=list(categories.values()), yticklabels=list(categories.values()), ylabel='Annotation', xlabel='Prediction')\n",
    "    # Rotate the tick labels and set their alignment\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    # Loop over data dimensions and create text annotations\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], '.2f'), ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\", fontsize=int(20-pow(len(categories), 0.5)))\n",
    "    fig.tight_layout()\n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "model.load_weights('/kaggle/working/model.keras')\n",
    "y_true, y_pred = [], []\n",
    "for ann in anns_valid:\n",
    "    # Load image\n",
    "    image = load_geoimage(ann.filename)\n",
    "    for obj_pred in ann.objects:\n",
    "        # Generate prediction\n",
    "        warped_image = np.expand_dims(image, 0)\n",
    "        predictions = model.predict(warped_image, verbose=0)\n",
    "        # Save prediction\n",
    "        pred_category = list(categories.values())[np.argmax(predictions)]\n",
    "        pred_score = np.max(predictions)\n",
    "        y_true.append(obj_pred.category)\n",
    "        y_pred.append(pred_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(categories.values()))\n",
    "draw_confusion_matrix(cm, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute the accuracy\n",
    "correct_samples_class = np.diag(cm).astype(float)\n",
    "total_samples_class = np.sum(cm, axis=1).astype(float)\n",
    "total_predicts_class = np.sum(cm, axis=0).astype(float)\n",
    "print('Mean Accuracy: %.3f%%' % (np.sum(correct_samples_class) / np.sum(total_samples_class) * 100))\n",
    "acc = correct_samples_class / np.maximum(total_samples_class, np.finfo(np.float64).eps)\n",
    "print('Mean Recall: %.3f%%' % (acc.mean() * 100))\n",
    "acc = correct_samples_class / np.maximum(total_predicts_class, np.finfo(np.float64).eps)\n",
    "print('Mean Precision: %.3f%%' % (acc.mean() * 100))\n",
    "for idx in range(len(categories)):\n",
    "    # True/False Positives (TP/FP) refer to the number of predicted positives that were correct/incorrect.\n",
    "    # True/False Negatives (TN/FN) refer to the number of predicted negatives that were correct/incorrect.\n",
    "    tp = cm[idx, idx]\n",
    "    fp = sum(cm[:, idx]) - tp\n",
    "    fn = sum(cm[idx, :]) - tp\n",
    "    tn = sum(np.delete(sum(cm) - cm[idx, :], idx))\n",
    "    # True Positive Rate: proportion of real positive cases that were correctly predicted as positive.\n",
    "    recall = tp / np.maximum(tp+fn, np.finfo(np.float64).eps)\n",
    "    # Precision: proportion of predicted positive cases that were truly real positives.\n",
    "    precision = tp / np.maximum(tp+fp, np.finfo(np.float64).eps)\n",
    "    # True Negative Rate: proportion of real negative cases that were correctly predicted as negative.\n",
    "    specificity = tn / np.maximum(tn+fp, np.finfo(np.float64).eps)\n",
    "    # Dice coefficient refers to two times the intersection of two sets divided by the sum of their areas.\n",
    "    # Dice = 2 |A∩B| / (|A|+|B|) = 2 TP / (2 TP + FP + FN)\n",
    "    f1_score = 2 * ((precision * recall) / np.maximum(precision+recall, np.finfo(np.float64).eps))\n",
    "    print('> %s: Recall: %.3f%% Precision: %.3f%% Specificity: %.3f%% Dice: %.3f%%' % (list(categories.values())[idx], recall*100, precision*100, specificity*100, f1_score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing\n",
    "Try to improve the results provided in the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJr_-xCt-AM-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "anns = []\n",
    "for (dirpath, dirnames, filenames) in os.walk('../input/xview-dataset/xview_recognition/xview_test'):\n",
    "    for filename in filenames:\n",
    "        image_path = os.path.relpath(os.path.join(dirpath, filename), '../input/xview-dataset/xview_recognition/')\n",
    "        image = GenericImage(image_path)\n",
    "        image.tile = np.array([0, 0, 224, 224])\n",
    "        obj = GenericObject()\n",
    "        obj.bb = (0, 0, 224, 224)\n",
    "        obj.category = dirpath[dirpath.rfind('/')+1:]\n",
    "        image.add_object(obj)\n",
    "        anns.append(image)\n",
    "print('Number of testing images: ' + str(len(anns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TGs2zqfv-AM_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "model.load_weights('/kaggle/working/model.keras')\n",
    "predictions_data = {\"images\": {}, \"annotations\": {}}\n",
    "for idx, ann in enumerate(anns):\n",
    "    image_data = {\"image_id\": ann.filename.split('/')[-1], \"filename\": ann.filename, \"width\": int(ann.tile[2]), \"height\": int(ann.tile[3])}\n",
    "    predictions_data[\"images\"][idx] = image_data\n",
    "    # Load image\n",
    "    image = load_geoimage(ann.filename)\n",
    "    for obj_pred in ann.objects:\n",
    "        # Generate prediction\n",
    "        warped_image = np.expand_dims(image, 0)\n",
    "        predictions = model.predict(warped_image, verbose=0)\n",
    "        # Save prediction\n",
    "        pred_category = list(categories.values())[np.argmax(predictions)]\n",
    "        pred_score = np.max(predictions)\n",
    "        annotation_data = {\"image_id\": ann.filename.split('/')[-1], \"category_id\": pred_category, \"bbox\": [int(x) for x in obj_pred.bb]}\n",
    "        predictions_data[\"annotations\"][idx] = annotation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(\"/kaggle/working/prediction.json\", \"w\") as outfile:\n",
    "    json.dump(predictions_data, outfile)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6719064,
     "sourceId": 10821714,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
